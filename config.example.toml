
# ─────────────────────────────────────────────
# Agent settings
# ─────────────────────────────────────────────
[agent]

# Provider selection (default: openai)
#
#   openai              → OpenAI API      (default model: gpt-4o, OAuth PKCE or API key)
#   anthropic / claude  → Anthropic       (default model: claude-sonnet-4-6, OAuth PKCE or API key)
#   together            → Together.ai     (default model: meta-llama/Llama-3.3-70B-Instruct-Turbo, API key)
#   ollama              → Local Ollama    (default model: llama3.2, no api_key required)
#   openrouter          → OpenRouter      (default model: openai/gpt-4o, OAuth PKCE or API key)
#   custom              → specify base_url / model directly
#
# The OpenAI preset supports both the standard ChatCompletions API and the Responses API
# (/v1/responses) for ChatGPT Pro subscribers.
# The Anthropic preset handles OAuth Bearer auth and tool name sanitization automatically.
#
provider = "openai"

# Model ID — leave blank to use the provider default
# Examples:
#   model = "gpt-4o"                                     # openai
#   model = "gpt-4o-mini"                                # openai (cheaper)
#   model = "claude-sonnet-4-6"                          # anthropic
#   model = "claude-opus-4-6"                            # anthropic (high performance)
#   model = "meta-llama/Llama-3.3-70B-Instruct-Turbo"   # together
#   model = "llama3.2"                                   # ollama
#   model = "openai/gpt-4o"                              # openrouter
model = ""

# API key — environment variables take precedence:
#   openpista_API_KEY    → applies to all providers (highest priority)
#   OPENAI_API_KEY       → openai / custom (fallback)
#   ANTHROPIC_API_KEY    → anthropic
#   TOGETHER_API_KEY     → together
#   OPENROUTER_API_KEY   → openrouter
#   GITHUB_COPILOT_TOKEN → GitHub Copilot (extension slot)
#   (ollama requires no API key)
api_key = ""

# Maximum number of tool-call rounds (default: 10)
max_tool_rounds = 10

# API base URL — automatically set when a provider is selected; usually not needed
# Only set this for the custom provider or to override the default base URL:
#   base_url = "http://localhost:11434/v1"   # if Ollama runs on a non-default port
#   base_url = "https://my-proxy.example.com/v1"
# base_url = ""

# OAuth 2.0 client ID (PKCE public client — not a secret)
# Required for browser-based OAuth login via `openpista auth login`
# Can also be set via the openpista_OAUTH_CLIENT_ID environment variable
# oauth_client_id = ""

# ─────────────────────────────────────────────
# Channel settings
# ─────────────────────────────────────────────
[channels.telegram]
enabled = false
token = ""  # or set the TELEGRAM_BOT_TOKEN environment variable

[channels.cli]
enabled = true

[channels.whatsapp]
enabled = false
session_dir = "~/.openpista/whatsapp-session"   # WhatsApp Web session auth state directory
# bridge_path = "whatsapp-bridge/index.js"      # Path to Node.js bridge script (optional)

[channels.web]
enabled = false
token = ""        # or set the openpista_WEB_TOKEN environment variable
port = 3210       # or set the openpista_WEB_PORT environment variable
cors_origins = "*"
static_dir = "~/.openpista/web"
shared_session_id = "shared-main"   # empty string falls back to per-client web:<client_id> sessions

# ─────────────────────────────────────────────
# Database / Skills path
# ─────────────────────────────────────────────
[database]
url = "~/.openpista/memory.db"

[skills]
workspace = "~/.openpista/workspace"
